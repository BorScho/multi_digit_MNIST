{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class SingleDigitMNISTNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SingleDigitMNISTNet, self).__init__()\n",
    "        # input MNIST images for nof_digits digit-image: 1 x nof_digitsx28 x nof_digitsx28\n",
    "        self.numChannels1 = 8\n",
    "        self.numChannels2 = 32\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(1, self.numChannels1, 5, padding=2, bias=False) # <- out: 8 x 28 x 28  # <- max-pooling out: 8 x 14 x 14\n",
    "        self.conv1_batchnorm = torch.nn.BatchNorm2d(num_features = self.numChannels1)\n",
    "        \n",
    "        # use normal initialization for conv1:\n",
    "        torch.nn.init.normal_(self.conv1.weight)\n",
    "        torch.nn.init.constant_(self.conv1_batchnorm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.conv1_batchnorm.bias)\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(self.numChannels1, self.numChannels2, 3, padding=1, bias=False) #<- out: 32 x 14 x 14\n",
    "        self.conv2_batchnorm = torch.nn.BatchNorm2d(num_features = self.numChannels2)\n",
    "\n",
    "         # use normal initialization for conv2:\n",
    "        torch.nn.init.normal_(self.conv2.weight)\n",
    "        torch.nn.init.constant_(self.conv2_batchnorm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.conv2_batchnorm.bias)\n",
    "\n",
    "        nof_classes = 11 # figures 0...9 and \"not recognized\"\n",
    "        self.fc1 = torch.nn.Linear(self.numChannels2 *7 * 7, 256)\n",
    "        self.fc2 = torch.nn.Linear(256, 11)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1_batchnorm(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(x), (2,2))\n",
    "        x = self.conv2_batchnorm(self.conv2(x))\n",
    "        x = F.max_pool2d(F.relu(x), (2,2))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(x, dim=1) # use log_softmax() (i.e. log(softmax()) ) to use NLLLoss() as loss-function\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pseudo_img_batch.shape: torch.Size([2, 1, 28, 28])\n",
      "model output shape: torch.Size([2, 11])\n",
      "sum is equal (zero,zero)? : tensor([-26.4055, -26.3921], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# check the network-definition:\n",
    "\n",
    "pseudo_img_batch = torch.rand(2,1,28,28)\n",
    "print(f\"pseudo_img_batch.shape: {pseudo_img_batch.shape}\")\n",
    "\n",
    "tmodel = SingleDigitMNISTNet()\n",
    "toutput = tmodel(pseudo_img_batch)\n",
    "print(f\"model output shape: {toutput.shape}\")\n",
    "print(f\"sum is equal (zero,zero)? : {toutput.sum(dim=1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training(epochs, train_loader, model, loss_fn, optimizer, device, show_progress= False, L2_regularization=False, L1_regularization=False, L2_lambda=0.001, L1_lambda=0.001):\n",
    "    l2_norm = 0\n",
    "    l1_norm = 0\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, y in train_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            yp = model(imgs)\n",
    "            loss = loss_fn(yp, y)\n",
    "            \n",
    "            if(L2_regularization):\n",
    "                l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "                loss = loss + L2_lambda * l2_norm\n",
    "            \n",
    "            if(L1_regularization):\n",
    "                l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "                loss = loss + L1_lambda * l1_norm\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if(epoch == 1 or epoch%10 == 0):\n",
    "            print(F\"len train loader: {len(train_loader)}\")\n",
    "            print(f\"{datetime.datetime.now()} Epoch {epoch} Training loss {loss_train/ len(train_loader)}\")\n",
    "            if(show_progress): # prints out some weights to see if anything happens at all:\n",
    "                print(model.conv1.weight[0][0:10])\n",
    "\n",
    "\n",
    "def validate(model, train_loader, val_loader, loss_fn):\n",
    "    model.eval()\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        equals = 0\n",
    "        nof_y = 0\n",
    "        for imgs, y  in loader:\n",
    "            with torch.no_grad():\n",
    "                yp = model(imgs)\n",
    "                y_class = torch.argmax(yp, dim=1)\n",
    "                #print(f\"y.shape: {y.shape}\")\n",
    "                #print(f\"y_class.shape: {y_class.shape}\")\n",
    "                equals += torch.eq(y_class, y).sum()\n",
    "                nof_y += len(y)\n",
    "        \n",
    "        print(f\"Accuracy {name}: {equals/nof_y}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
      "        4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
      "        4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3])\n"
     ]
    }
   ],
   "source": [
    "for imgs, y in test_dl:\n",
    "    print(len(y))\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n",
      "len train loader: 938\n",
      "2022-01-27 15:55:51.818228 Epoch 1 Training loss 16.19423073339564\n",
      "len train loader: 938\n",
      "2022-01-27 16:08:54.460777 Epoch 10 Training loss 2.8628625328352713\n",
      "len train loader: 938\n",
      "2022-01-27 16:22:20.027360 Epoch 20 Training loss 2.872350185156377\n",
      "len train loader: 938\n",
      "2022-01-27 16:34:59.643368 Epoch 30 Training loss 2.887605108686093\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "# training:\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device {device}\")\n",
    "\n",
    "# load datasets and create dataloader for BATCH_SIZE\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dl = DataLoader(training_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = \"data\",\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "# start with a new model each time:\n",
    "model = None\n",
    "model = SingleDigitMNISTNet().to(device=device)\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=1e-5) # this optimizer is divergent most of the time leading to nan-size loss!\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "loss_fn = torch.nn.NLLLoss() # our model outputs log_softmax(), i.e. we can use NLLLoss() here\n",
    "\n",
    "training(\n",
    "    epochs = 30,\n",
    "    train_loader = train_dl,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    optimizer = optimizer,\n",
    "    device = device,\n",
    "    show_progress = False,\n",
    "    L2_regularization = True,\n",
    "    L1_regularization = True,\n",
    "    L1_lambda=0.01    \n",
    ")\n",
    "\n",
    "print(\"Training finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save, load the model via it's state-dict:\n",
    "\n",
    "import os\n",
    "\n",
    "#MODE=\"load\"\n",
    "MODE=\"save\"\n",
    "\n",
    "MODEL_PATH = os.path.join(os.getcwd(), \"simplesaved_model.pt\")\n",
    "\n",
    "if( MODE==\"save\"):\n",
    "    torch.save(model.state_dict(), MODEL_PATH)\n",
    "\n",
    "if ( MODE == \"load\"):\n",
    "    #Load with this code:\n",
    "    model = SingleDigitMNISTNet(*args, **kwargs)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "    model.eval()\n",
    "\n",
    "print(f\"Finished {MODE}ing the model to {MODEL_PATH}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save, load the model using TorchScript:\n",
    "# Using the TorchScript format, you will be able to load the exported model and run inference without defining the model class.\n",
    "# https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-across-devices\n",
    "\n",
    "import os\n",
    "\n",
    "MODEL_PATH = os.path.join(os.getcwd(), \"simplesaved_model.pt\")\n",
    "\n",
    "# chose load or save:\n",
    "#MODE=\"load\"\n",
    "MODE=\"save\"\n",
    "\n",
    "if( MODE==\"save\"):\n",
    "    model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "    model_scripted.save(MODEL_PATH) # Save\n",
    "\n",
    "if ( MODE == \"load\"):\n",
    "    model = torch.jit.load(MODEL_PATH)\n",
    "    model.eval() # call to prepare for inference - i.e. non-training\n",
    "\n",
    "print(f\"Finished {MODE}ing the model to {MODEL_PATH}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 7.187633037567139\n",
      "Accuracy val: 7.229299545288086\n",
      "Validation finished.\n"
     ]
    }
   ],
   "source": [
    "validate(\n",
    "    model = model,\n",
    "    train_loader = train_dl,\n",
    "    val_loader = test_dl, \n",
    "    loss_fn = loss_fn\n",
    ")\n",
    "\n",
    "print(\"Validation finished.\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e3b78e97e18c72126c3c5b3e515c7ce053012eba14c4d1ae01d8c98942b8394"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('conenv_multiMnist': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
