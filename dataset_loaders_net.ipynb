{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Dataset for Multi-digit-MNIST Images ####\n",
    "<br>\n",
    "We have to generate data in a train and test set still. Or can we split data into train and test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDigitMNISTDataset(Dataset):\n",
    "    def __init__(self, source_dir, img_transform=None, label_transform=None, merge_point_transform=None):\n",
    "        self.source_dir = source_dir\n",
    "        self.img_transform = img_transform\n",
    "        self.label_transform = label_transform\n",
    "        self.merge_point_transform = merge_point_transform\n",
    "        \n",
    "        self.data_record_entries = []\n",
    "        cwd = os.getcwd()\n",
    "        self.source_path = os.path.join(cwd, self.source_dir)\n",
    "        with os.scandir(self.source_path) as it:\n",
    "            for entry in it:\n",
    "                if entry.is_file() and entry.name.endswith(\".pt\"):\n",
    "                    self.data_record_entries.append(entry)\n",
    "        \n",
    "        self.data_records = []\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_record_entries)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_record = torch.load(os.path.join(self.source_path, self.data_record_entries[idx].name))\n",
    "        multi_img = data_record[\"multi_img\"]\n",
    "        multi_img_label = data_record[\"multi_img_label\"]\n",
    "        merge_points = data_record[\"merge_points\"]\n",
    "        if self.img_transform:\n",
    "            multi_img = self.img_transform(multi_img)\n",
    "        if self.label_transform:\n",
    "            multi_img_label = self.label_transform(multi_img_label) \n",
    "        if self.merge_point_transform:\n",
    "            merge_points = self.merge_point_transform(merge_points)\n",
    "        \n",
    "        return multi_img, multi_img_label, merge_points\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import dataloader\n",
    "\n",
    "mmnist_ds = MultiDigitMNISTDataset(source_dir=\"Mnist4\")\n",
    "train_dl = Dataloader(mmnist_ds, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Neural Net to learn finding the merge-points ###\n",
    "<br>\n",
    "At first we presume, that we know the number of merge-points and ask only for their x-coordinate\n",
    "<br>\n",
    "These coordinates will be used to split the image of the multi-digit number into single-digit numbers, <br>\n",
    "leaving us with an standard MNIST-like problem for which there are good solutions available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "\n",
    "class MultiDigitMNISTNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, nof_digits):\n",
    "        super(self).__init__()\n",
    "        # input MNIST images: 1 x 28 x 28\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        # out: 6 x 24 x 24\n",
    "        # max-pooling: 6 x 12 x 12\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 3)\n",
    "        # out: (6 x ?: no!) 16 x 10 x 10 \n",
    "        # max-pooling: 16 x 5 x 5\n",
    "        self.fc1 = torch.nn.linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = torch.nn.linear(120, nof_digits)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        x = torch.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e3b78e97e18c72126c3c5b3e515c7ce053012eba14c4d1ae01d8c98942b8394"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('conenv_multiMnist': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
